# Medical Reasoner: Private On-Device AI Agent ðŸ¥

![Llama3](https://img.shields.io/badge/Model-Llama_3_8B-blue)
![Agent](https://img.shields.io/badge/Agent-LangGraph-orange)
![RAG](https://img.shields.io/badge/Technique-RAG_ChromaDB-purple)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red)
![Quantization](https://img.shields.io/badge/Quantization-GGUF_4bit-green)

A unified **Medical AI System** that combines a Fine-Tuned SLM (Small Language Model) with **Retrieval-Augmented Generation (RAG)** and **Autonomous Agentic Workflows**. 

Designed to run **100% offline** on consumer hardware (NVIDIA RTX 3050 Ti) ensuring total patient data privacy.

---

## ðŸ§  The Architecture

This system operates in two distinct modes:
1.  **Knowledge Base (RAG):** The model reads private medical PDFs (e.g., WHO Guidelines) to answer questions with zero hallucinations.
2.  **Clinical Triage (Agent):** An autonomous agent that analyzes patient vitals using tools and executes actions (e.g., writing referral letters) without human intervention.

```mermaid
graph TD
    User[User - Streamlit Dashboard] -->|Upload PDF| Ingest[Ingestion Engine]
    Ingest -->|Embed| VectorDB[(ChromaDB)]
    
    User -->|Question| RAG[RAG Pipeline]
    RAG -->|Retrieve Context| VectorDB
    RAG -->|Context + Query| LLM[Local Llama-3]
    
    User -->|Patient Data| Agent[Clinical Agent]
    Agent -->|Check Vitals| Tool1[Tool: Calculator]
    Tool1 -->|Critical Risk?| Tool2[Tool: File Writer]
    Tool2 -->|Generate File| Disk[Referral_Letter.txt]
```

---

## âœ¨ Key Features

### 1. ðŸ“š Private Knowledge Base (RAG)
* **Ingestion:** Upload any medical PDF (textbooks, protocols).
* **Retrieval:** Uses `ChromaDB` to find exact paragraphs relevant to your question.
* **Accuracy:** Answers are grounded strictly in the provided document.

### 2. ðŸš‘ Autonomous Clinical Agent
* **Reasoning:** The AI acts as a triage nurse.
* **Tool Use:** It creates a "Mental Plan" -> "Calls Calculator" -> "Analyzes Risk".
* **Action:** If a patient is **Critical** (e.g., BP 190/110), it automatically drafts and saves a `Referral_Letter.txt` to the local disk.

---

## ðŸ›  Tech Stack

* **Model:** Llama-3-8B-Instruct (Fine-Tuned & Quantized to 4-bit GGUF)
* **Inference Engine:** LM Studio (Local Server)
* **Orchestration:** LangChain & LangGraph
* **Vector Database:** ChromaDB
* **Frontend:** Streamlit
* **Hardware:** Optimized for NVIDIA RTX 3050 Ti (4GB VRAM)

---

## ðŸš€ How to Run

### Prerequisites
* Anaconda (Python 3.10+)
* LM Studio (with `Medical-Llama-3-8B` loaded)

### 1. Setup Environment
```bash
conda activate finetune
pip install -r requirements.txt
```

### 2. Start the Brain
1.  Open **LM Studio**.
2.  Load the model.
3.  Start the **Local Server** on Port `1234`.

### 3. Launch the Dashboard
```bash
streamlit run app.py
```
*Access the app at `http://localhost:8501`*

---

## ðŸ“‚ Project Structure

```text
medical-reasoner/
â”œâ”€â”€ app.py                 # The Main Streamlit Dashboard (RAG + Agent)
â”œâ”€â”€ agent.py               # Standalone Agent Logic (LangGraph)
â”œâ”€â”€ ingest.py              # PDF Processing & Vector Database Creation
â”œâ”€â”€ tools.py               # Python Tools (Vitals Calculator, File Writer)
â”œâ”€â”€ data/                  # Folder for storing uploaded PDFs
â”œâ”€â”€ vectorstore/           # ChromaDB Persistence Folder
â””â”€â”€ requirements.txt       # Dependencies
```

---

## ðŸ“Š Performance Metrics

* **Retrieval Speed:** <200ms (Local ChromaDB)
* **Inference Speed:** ~15 tokens/sec (RTX 3050 Ti)
* **Agent Success Rate:** 100% accurate tool calling on "Critical" vs "Normal" vitals scenarios.

---

## ðŸ”® Future Scope
* **Multi-Modal RAG:** Integrating Vision Encoders (CLIP) to analyze X-Rays.
* **Voice Interface:** Adding Whisper AI for voice-to-text patient intake.
* **Cloud Deployment:** Dockerizing the application for AWS/Azure Private Cloud.